{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (open(\"corpus.txt\", encoding=\"utf-8\").read())\n",
    "text=text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "\n",
    "n_to_char ={n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100 #this is a parameter\n",
    "\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "82768/82768 [==============================] - 547s 7ms/step - loss: 2.9680\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=1, batch_size=100)\n",
    "\n",
    "model.save_weights('text_generator_400_0.2_400_0.2_baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('text_generator_400_0.2_400_0.2_baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' of the body,\\nor of the green leaf?\\ndo i have to whisper\\nmy every sin and grief?\\nif the wind passes the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wider Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(700, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(700))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 2.9679\n",
      "Epoch 2/5\n",
      "82768/82768 [==============================] - 1948s 24ms/step - loss: 2.6948\n",
      "Epoch 3/5\n",
      "82768/82768 [==============================] - 1922s 23ms/step - loss: 2.5679\n",
      "Epoch 4/5\n",
      "82768/82768 [==============================] - 2085s 25ms/step - loss: 2.4709\n",
      "Epoch 5/5\n",
      "82768/82768 [==============================] - 2155s 26ms/step - loss: 2.3942\n"
     ]
    }
   ],
   "source": [
    "# model.fit(X_modified, Y_modified, epochs=100, batch_size=50)\n",
    "\n",
    "# model.save_weights('text_generator_gigantic.h5')\n",
    "\n",
    "\n",
    "model.fit(X_modified, Y_modified, epochs=5, batch_size=50)\n",
    "# model.fit_generator(gen(), steps_per_epoch=X_modified.shape[0] // 50,epochs=100, verbose=1, workers=2, use_multiprocessing=True)\n",
    "\n",
    "model.save_weights('text_generator_700_0.2_700_0.2_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('text_generator_700_0.2_700_0.2_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' of the body,\\nor of the green leaf?\\ndo i have to whisper\\nmy every sin and grief?\\nif the wind passes the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia the suiet of the sia t'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wider 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(700, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(700))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "82768/82768 [==============================] - 2117s 26ms/step - loss: 2.8840\n",
      "Epoch 2/15\n",
      "82768/82768 [==============================] - 2112s 26ms/step - loss: 2.6065\n",
      "Epoch 3/15\n",
      "82768/82768 [==============================] - 2109s 25ms/step - loss: 2.4596\n",
      "Epoch 4/15\n",
      "82768/82768 [==============================] - 2104s 25ms/step - loss: 2.3440\n",
      "Epoch 5/15\n",
      "82768/82768 [==============================] - 2096s 25ms/step - loss: 2.2421\n",
      "Epoch 6/15\n",
      "82768/82768 [==============================] - 2088s 25ms/step - loss: 2.1488\n",
      "Epoch 7/15\n",
      "82768/82768 [==============================] - 2080s 25ms/step - loss: 2.0563\n",
      "Epoch 8/15\n",
      "82768/82768 [==============================] - 2071s 25ms/step - loss: 1.9526\n",
      "Epoch 9/15\n",
      "82768/82768 [==============================] - 2078s 25ms/step - loss: 1.8492\n",
      "Epoch 10/15\n",
      "82768/82768 [==============================] - 2061s 25ms/step - loss: 1.7462\n",
      "Epoch 11/15\n",
      "82768/82768 [==============================] - 2022s 24ms/step - loss: 1.6386\n",
      "Epoch 12/15\n",
      "82768/82768 [==============================] - 1924s 23ms/step - loss: 1.5318\n",
      "Epoch 13/15\n",
      "82768/82768 [==============================] - 1924s 23ms/step - loss: 1.4236\n",
      "Epoch 14/15\n",
      "82768/82768 [==============================] - 1925s 23ms/step - loss: 1.3241\n",
      "Epoch 15/15\n",
      "82768/82768 [==============================] - 1924s 23ms/step - loss: 1.2261\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=15, batch_size=50)\n",
    "# model.fit_generator(gen(), steps_per_epoch=X_modified.shape[0] // 50,epochs=100, verbose=1, workers=2, use_multiprocessing=True)\n",
    "\n",
    "model.save_weights('wider_text_generator_700_0.2_700_0.2_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('wider_text_generator_700_0.2_700_0.2_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_mapped = X[95]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am i of the body,\\nor of the green leaf?\\ndo i have to whisper\\nmy every sin and grief?\\nif the wind passed tie sea,\\nand i am dumb to tell the beauty steet\\n\\tof the oight, \\nand the tpoder spon the darken blay\\nand will not reer.\\nthere is a soice whose feet, this are their souls ies heart with shee in the sile was thee not the sain,\\n\\tthe beauty whth the sing was the silent of dead leaves\\nthe soun to measu is in the sile was the soun to measu is in the soiee\\nof the deep stars of men\\nthe soul of mowe and'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2=\"\"\n",
    "for char in full_string:\n",
    "    txt2 = txt2+char\n",
    "txt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gigantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(700, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(700))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/41\n",
      "82768/82768 [==============================] - 1919s 23ms/step - loss: 2.8642\n",
      "Epoch 2/41\n",
      "82768/82768 [==============================] - 1918s 23ms/step - loss: 2.5919\n",
      "Epoch 3/41\n",
      "82768/82768 [==============================] - 1991s 24ms/step - loss: 2.4492\n",
      "Epoch 4/41\n",
      "82768/82768 [==============================] - 1933s 23ms/step - loss: 2.3334\n",
      "Epoch 5/41\n",
      "82768/82768 [==============================] - 1947s 24ms/step - loss: 2.2395\n",
      "Epoch 6/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 2.1472\n",
      "Epoch 7/41\n",
      "82768/82768 [==============================] - 1929s 23ms/step - loss: 2.0620\n",
      "Epoch 8/41\n",
      "82768/82768 [==============================] - 1924s 23ms/step - loss: 1.9712\n",
      "Epoch 9/41\n",
      "82768/82768 [==============================] - 1919s 23ms/step - loss: 1.8692\n",
      "Epoch 10/41\n",
      "82768/82768 [==============================] - 1919s 23ms/step - loss: 1.7628\n",
      "Epoch 11/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 1.6569\n",
      "Epoch 12/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 1.5476\n",
      "Epoch 13/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 1.4359\n",
      "Epoch 14/41\n",
      "82768/82768 [==============================] - 1919s 23ms/step - loss: 1.3368\n",
      "Epoch 15/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 1.2477\n",
      "Epoch 16/41\n",
      "82768/82768 [==============================] - 1946s 24ms/step - loss: 1.1560\n",
      "Epoch 17/41\n",
      "82768/82768 [==============================] - 1923s 23ms/step - loss: 1.0860\n",
      "Epoch 18/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 1.0109\n",
      "Epoch 19/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 0.9478\n",
      "Epoch 20/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 0.8985\n",
      "Epoch 21/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 0.8531\n",
      "Epoch 22/41\n",
      "82768/82768 [==============================] - 1935s 23ms/step - loss: 0.8049\n",
      "Epoch 23/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 0.7744\n",
      "Epoch 24/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 0.7385\n",
      "Epoch 25/41\n",
      "82768/82768 [==============================] - 1921s 23ms/step - loss: 0.7239\n",
      "Epoch 26/41\n",
      "82768/82768 [==============================] - 1921s 23ms/step - loss: 0.6923\n",
      "Epoch 27/41\n",
      "82768/82768 [==============================] - 1936s 23ms/step - loss: 0.6705\n",
      "Epoch 28/41\n",
      "82768/82768 [==============================] - 1934s 23ms/step - loss: 0.6513\n",
      "Epoch 29/41\n",
      "82768/82768 [==============================] - 1922s 23ms/step - loss: 0.6562\n",
      "Epoch 30/41\n",
      "82768/82768 [==============================] - 1921s 23ms/step - loss: 1.7651\n",
      "Epoch 31/41\n",
      "82768/82768 [==============================] - 1920s 23ms/step - loss: 0.7784\n",
      "Epoch 32/41\n",
      "82768/82768 [==============================] - 1921s 23ms/step - loss: 0.6110\n",
      "Epoch 33/41\n",
      "82768/82768 [==============================] - 1921s 23ms/step - loss: 0.6223\n",
      "Epoch 34/41\n",
      "82768/82768 [==============================] - 1921s 23ms/step - loss: 0.6225\n",
      "Epoch 35/41\n",
      "82768/82768 [==============================] - 1921s 23ms/step - loss: 0.6361\n",
      "Epoch 36/41\n",
      "82768/82768 [==============================] - 1921s 23ms/step - loss: 0.6355\n",
      "Epoch 37/41\n",
      "82768/82768 [==============================] - 1921s 23ms/step - loss: 0.6275\n",
      "Epoch 38/41\n",
      "82768/82768 [==============================] - 1921s 23ms/step - loss: 0.6158\n",
      "Epoch 39/41\n",
      "82768/82768 [==============================] - 1950s 24ms/step - loss: 0.6444\n",
      "Epoch 40/41\n",
      "82768/82768 [==============================] - 1924s 23ms/step - loss: 0.6487\n",
      "Epoch 41/41\n",
      "82768/82768 [==============================] - 1922s 23ms/step - loss: 0.6207\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=41, batch_size=50)\n",
    "# model.fit_generator(gen(), steps_per_epoch=X_modified.shape[0] // 50,epochs=100, verbose=1, workers=2, use_multiprocessing=True)\n",
    "\n",
    "model.save_weights('gigantic_text_generator_700_0.2_700_0.2_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('gigantic_text_generator_700_0.2_700_0.2_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_mapped = X[2006]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"s in the heart.\\nthe country that is my country\\n\\tis earth: its men.\\n\\tis sky: the love within their hearts that flias,\\nbut in the floom so dispel the gloom\\nand the siake of men,\\nthe cark thou wtill ig treads that mike my eare for fame or hain that resanens on the ground. as ree as human bearty show,\\nwhat dii uito me touth and kife,\\n\\twasching cries ttill line and mem'ry haa no sting and the bay\\nthe familiar noisy tread of hob-nailed booweh\\nmy heart: fo the mortoing streams\\nturns mine the stord of m\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt3=\"\"\n",
    "for char in full_string:\n",
    "    txt3 = txt3+char\n",
    "txt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
